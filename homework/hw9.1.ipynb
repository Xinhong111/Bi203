{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import bebi103\n",
    "\n",
    "import os.path\n",
    "\n",
    "import bokeh.io\n",
    "import bokeh.plotting\n",
    "import bokeh.layouts\n",
    "bokeh.io.output_notebook()\n",
    "\n",
    "color_palette=['#4e79a7', '#f28e2b', '#e15759', '#76b7b2', '#59a14f', '#edc948', '#b07aa1', '#ff9da7', '#9c755f', '#bab0ac']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data and take a look\n",
    "df = pd.read_csv('../data/hw_4.2_caulobacter_growth_image_processing_results.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the length of division is different for all growth events we should add another column that restarts the time count from 0 every time there's a division."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a new column that makes the time go back to 0 at every start of growth\n",
    "time = []\n",
    "j = 0\n",
    "for i in df['growth_event'].diff():\n",
    "    if i == 0:\n",
    "        j += 1\n",
    "        time.append(j)\n",
    "    else:\n",
    "        j = 0\n",
    "        time.append(j)\n",
    "\n",
    "df['t'] = time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename for convenience\n",
    "df = df.rename(columns={'area (sq um)': 'area'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with a subset of the data first. We will look at bacterium 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice out the data for bacterium 1\n",
    "df_bacterium1 = df.loc[df['bacterium'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's plot the data of bacterium to take a look first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = bokeh.plotting.figure(plot_width=650,\n",
    "                          plot_height=250,\n",
    "                          x_axis_label='time (min)',\n",
    "                          y_axis_label='cell area (sq Âµm)')\n",
    "\n",
    "# Specify the glyphs\n",
    "colors = ['#1f78b4', '#a6cee3']\n",
    "for i, g in df_bacterium1.groupby('growth_event'):\n",
    "    p.circle(g['time (min)'], g['area'], size=3, color=colors[i%2])\n",
    "\n",
    "bokeh.io.show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decided to start our analysis with a non-hierachical model first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No hierarchy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just model a single growth event for now with no hierarchy using the exponential model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prior for the non-hierachical exponential model\n",
    "def data_prior_pred(t):\n",
    "    '''\n",
    "    Samples parameter values according to the prior and generates\n",
    "    data y at the values given in t.\n",
    "    '''\n",
    "    # Sample parameter values according to priors\n",
    "    a = np.random.normal(1.4, 0.3)\n",
    "    k = np.random.normal(0.01, 0.002)\n",
    "    sigma = np.abs(np.random.normal(0, 0.1))\n",
    "    \n",
    "    # Generate random data according to the likelihood\n",
    "    return np.random.normal(a * np.exp(k * t), sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prior predictive check by plotting the simulated data\n",
    "p = bokeh.plotting.figure(height=300, width=450,\n",
    "                          x_axis_label='time',\n",
    "                          y_axis_label='area')\n",
    "\n",
    "t = df_bacterium1.loc[df_bacterium1['growth_event'] == 0, 't'].values\n",
    "\n",
    "# Plot simulated data\n",
    "for i in range(100):\n",
    "    p.circle(t, data_prior_pred(t), size=3, alpha=0.1)\n",
    "\n",
    "bokeh.io.show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This broad prior capture the trend of growth but definitly miss lots of information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try the non-hierachical linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the prior for non-hierachical linear model\n",
    "def data_prior_pred_linear(t):\n",
    "    '''\n",
    "    Samples parameter values according to the prior and generates\n",
    "    data y at the values given in t.\n",
    "    '''\n",
    "    # Sample parameter values according to priors\n",
    "    a = np.random.normal(1.4, 0.3)\n",
    "    b = np.random.normal(0.01, 0.003)\n",
    "    sigma = np.abs(np.random.normal(0, 0.1))\n",
    "    \n",
    "    # Generate random data according to the likelihood\n",
    "    return np.random.normal(a + b * t, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prior predictive check by plotting the simulated data\n",
    "p = bokeh.plotting.figure(height=300, width=450,\n",
    "                          x_axis_label='time',\n",
    "                          y_axis_label='area')\n",
    "\n",
    "t = df_bacterium1.loc[df_bacterium1['growth_event'] == 0, 't'].values\n",
    "\n",
    "# Plot simulated data\n",
    "for i in range(100):\n",
    "    p.circle(t, data_prior_pred_linear(t), size=3, alpha=0.1)\n",
    "\n",
    "bokeh.io.show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trend still capture the growth. But the single level model neglect a lots of information such as the variation between growth events and bacteriums. So let's consider the variation between growth event first and build a two-level hierarchical model for one of the bacterium."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Two level hierarchical model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try a two level hierarchical model for bacterium 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But before we do anything, we would like to construct a function to plot the predictive data. Because in this case, when you think of the growth event, every data point has a corespondence time, if we just use a simple predictive ECDF, we will lose all the information of the time, which dosen't make sense. In order to plot the time-series predictive data, we constucted a similar function when we did HW9.2, so we would like to also use this function below here. The detailed description of this function is in hw9.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot the predictive data\n",
    "def hw92_predictive(df, x, y=None, namex='index_1', name='F_ppc', perc=[80, 60, 40, 20], \n",
    "                    x_axis_label=None, y_axis_label=None, title=None, plot_width=350, plot_height=225, \n",
    "                    color='blue', data_color=color_palette[1], diff=False, p=None, baseline=0):\n",
    "    '''Mimic of predictive ECDF for sampling results with input variables\n",
    "    df - MCMC sampling data frame\n",
    "    x - input variable\n",
    "    y - data\n",
    "    namex - name of the input varible in the data frame\n",
    "    name - name of the predictive results in the data frame\n",
    "    perc - list, default [80, 60, 40, 20]\n",
    "            Percentiles for making colored envelopes for confidence\n",
    "            intervals for the predictive ECDFs. Maximally four can be \n",
    "            specified.'''\n",
    "    \n",
    "    #Copied from predictive ECDF, choose color\n",
    "    if color not in ['green', 'blue', 'red', 'gray',\n",
    "                     'purple', 'orange', 'betancourt']:\n",
    "        raise RuntimeError(\"Only allowed colors are 'green', 'blue', 'red', 'gray', 'purple', 'orange'\")\n",
    "    \n",
    "    colors = {'blue': ['#9ecae1','#6baed6','#4292c6','#2171b5','#084594'],\n",
    "              'green': ['#a1d99b','#74c476','#41ab5d','#238b45','#005a32'],\n",
    "              'red': ['#fc9272','#fb6a4a','#ef3b2c','#cb181d','#99000d'],\n",
    "              'orange': ['#fdae6b','#fd8d3c','#f16913','#d94801','#8c2d04'],\n",
    "              'purple': ['#bcbddc','#9e9ac8','#807dba','#6a51a3','#4a1486'],\n",
    "              'gray': ['#bdbdbd','#969696','#737373','#525252','#252525'],\n",
    "              'betancourt': ['#DCBCBC', '#C79999', '#B97C7C',\n",
    "    \n",
    "                             '#A25050', '#8F2727', '#7C0000']}\n",
    "    #Initialize the figure if needed\n",
    "    if p is None:\n",
    "        p = bokeh.plotting.figure(plot_width=plot_width,\n",
    "                                  plot_height=plot_height,\n",
    "                                  x_axis_label=x_axis_label,\n",
    "                                  y_axis_label=y_axis_label,\n",
    "                                  title=title)\n",
    "    \n",
    "    # If diff, take the difference of each step\n",
    "    if diff:\n",
    "        x = x[1:]\n",
    "        if y is not None:\n",
    "            y = np.diff(y)\n",
    "        Nb = len(x)\n",
    "        y_ppc = np.empty((len(perc) * 2 + 1, Nb))\n",
    "        for i in range(Nb):\n",
    "            # Take all the sampling results for each time point\n",
    "            temp = df.loc[df[namex]== i+2, name].values - df.loc[df[namex]== i+1, name].values\n",
    "            # Take the median and corresponding percentile\n",
    "            y_ppc[-1, i] = np.median(temp)\n",
    "            for j in range(len(perc)):\n",
    "                y_ppc[j * 2, i] = np.percentile(temp, 50 - perc[j] / 2)\n",
    "                y_ppc[j * 2 + 1, i] = np.percentile(temp, 50 + perc[j] / 2)\n",
    "    else:                \n",
    "        Nb = len(x)\n",
    "        y_ppc = np.empty((len(perc) * 2 + 1, Nb))\n",
    "        for i in range(Nb):\n",
    "            # Take all the sampling results for each time point\n",
    "            temp = df.loc[df[namex]== i+1+baseline, name].values\n",
    "            # Take all the sampling results for each time point\n",
    "            y_ppc[-1, i] = np.median(temp)\n",
    "            for j in range(len(perc)):\n",
    "                y_ppc[j * 2, i] = np.percentile(temp, 50 - perc[j] / 2)\n",
    "                y_ppc[j * 2 + 1, i] = np.percentile(temp, 50 + perc[j] / 2)\n",
    "    \n",
    "    # Plot\n",
    "    for j in range(len(perc)):\n",
    "        bebi103.viz.fill_between(x, y_ppc[j * 2, :],\n",
    "                     x, y_ppc[j * 2 + 1,:],\n",
    "                     p=p,\n",
    "                     show_line=False,\n",
    "                     fill_color=colors[color][j])\n",
    "        \n",
    "    p.circle(x, y_ppc[-1, :],\n",
    "           size=4,\n",
    "           color=colors[color][-1])\n",
    "    \n",
    "    if y is not None:\n",
    "        p.circle(x, y[baseline:baseline+Nb], size=4, color='orange')\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code up the prior predictive check for the two-level linear model. Our model is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{gather}\n",
    "a_0 \\sim \\mbox{Norm}(a_{hyper}, \\sigma_a) \\\\\n",
    "k \\sim \\mbox{Norm}(k_{hyper}, \\sigma_k) \\\\\n",
    "\\tau_a \\sim \\mbox{HalfNorm}(\\tau_{a, hyper}) \\\\\n",
    "\\tau_k \\sim \\mbox{HalfNorm}(\\tau_{k, hyper}) \\\\\n",
    "\\sigma_0 \\sim \\mbox{HalfNorm}(\\sigma_{hyper}) \\\\\n",
    "a_{01} \\sim \\mbox{Norm}(a_0, \\tau_a) \\\\\n",
    "k_1 \\sim \\mbox{Norm}(k, \\tau_k) \\\\\n",
    "a_{temp}(t) = a_{01} + {k_1 t} \\\\\n",
    "a(t) \\sim \\mbox{Norm}(a_{temp}(t), \\sigma_0)\\\\\n",
    "\\end{gather}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_code_pri_pred = \"\"\"\n",
    "data {\n",
    "  // Total Number of data points \n",
    "  int N;\n",
    "  \n",
    "  // Number of entries in each level of the hierarchy\n",
    "  int J_1;\n",
    "  int J_2;\n",
    "  vector[N] t;\n",
    "  \n",
    "  \n",
    "  // Input of parameters of the priors\n",
    "  real hyper_a0_mu;\n",
    "  real hyper_a0_sigma;\n",
    "  \n",
    "  real hyper_k0_mu;\n",
    "  real hyper_k0_sigma;\n",
    "  \n",
    "  real hyper_a0_tau;\n",
    "  real hyper_k0_tau;\n",
    "  \n",
    "  real hyper_sigma;\n",
    "}\n",
    "\n",
    "\n",
    "generated quantities {\n",
    "  // Total number of data points \n",
    "  real area[N * J_1];\n",
    "  \n",
    "  // Priors\n",
    "  real a0 = normal_rng(hyper_a0_mu, hyper_a0_sigma);\n",
    "  real k0 = normal_rng(hyper_k0_mu, hyper_k0_sigma);\n",
    "  \n",
    "  real a0_tau = fabs(normal_rng(0, hyper_a0_tau));\n",
    "  real k0_tau = fabs(normal_rng(0, hyper_k0_tau));\n",
    "  \n",
    "  real sigma = fabs(normal_rng(0, hyper_sigma));\n",
    "  \n",
    "  // Second layer\n",
    "  real a_1[J_1]; \n",
    "  real k_1[J_1];\n",
    "  \n",
    "  for (i in 1:J_1) {\n",
    "    a_1[i] = normal_rng(a0, a0_tau);\n",
    "    k_1[i] = normal_rng(k0, k0_tau);\n",
    "    for (j in 1:N) {\n",
    "      area[(i - 1) * N + j] = normal_rng((a_1[i] + k_1[i] * t[j]), sigma);\n",
    "  }\n",
    "  }\n",
    "  \n",
    "  }\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile\n",
    "sm_gen = bebi103.stan.StanModel(file='hw91_model_code_pri_pred.Stan')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's specify the parameter for the prior and sample from the prior (two-level linear model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of iteration\n",
    "N_iter = 100\n",
    "T = [i for i in range (100)]\n",
    "\n",
    "\n",
    "data = dict(N=100,\n",
    "            J_1=2,\n",
    "            J_2=3,\n",
    "            t = T,\n",
    "            hyper_a0_mu=1.4,\n",
    "            hyper_a0_sigma=0.3,\n",
    "            hyper_k0_mu=0.01,\n",
    "            hyper_k0_sigma=0.002,\n",
    "            hyper_a0_tau=0.1,\n",
    "            hyper_k0_tau=0.001,\n",
    "            hyper_sigma = 0.1,\n",
    "           )\n",
    "\n",
    "# Sample\n",
    "df_pred = sm_gen.sampling(data=data,\n",
    "                     algorithm='Fixed_param',\n",
    "                     warmup=0,\n",
    "                     chains=1,\n",
    "                     iter=N_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's extract the 'area' from the sample we generated and take a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_samples = bebi103.stan.extract_array(df_pred, name='area')\n",
    "\n",
    "df_samples.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use the function we mentioned before to visualize the generated samples in a time-series manner. This is a good way to do prior predictive check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prior predictive check by visualzing the time-series generated data from our prior\n",
    "time = T\n",
    "\n",
    "p1 = hw92_predictive(df_samples, time, name='area', plot_width=500, plot_height=400)\n",
    "\n",
    "\n",
    "bokeh.io.show(p1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trend looks quite resonable, seems we could move on with the prior in hand for the two-level linear model.   \n",
    "But before that, let's also perform prior predictive check on the two-level exponential model.  \n",
    "\n",
    "Our two-level exponential model is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{gather}\n",
    "a_0 \\sim \\mbox{Norm}(a_{hyper}, \\sigma_a) \\\\\n",
    "k \\sim \\mbox{Norm}(k_{hyper}, \\sigma_k) \\\\\n",
    "\\tau_a \\sim \\mbox{HalfNorm}(\\tau_{a, hyper}) \\\\\n",
    "\\tau_k \\sim \\mbox{HalfNorm}(\\tau_{k, hyper}) \\\\\n",
    "\\sigma_0 \\sim \\mbox{HalfNorm}(\\sigma_{hyper}) \\\\\n",
    "a_{01} \\sim \\mbox{Norm}(a_0, \\tau_a) \\\\\n",
    "k_1 \\sim \\mbox{Norm}(k, \\tau_k) \\\\\n",
    "a_{temp}(t) = a_{01} + {k_1 t} \\\\\n",
    "a(t) \\sim \\mbox{Norm}(a_{temp}(t), \\sigma_0)\\\\\n",
    "\\end{gather}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's code up the Stan model for the prior predictive check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_code_pri_pred_ex = \"\"\"\n",
    "data {\n",
    "  // Total Number of data points \n",
    "  int N;\n",
    "  \n",
    "  // Number of entries in each level of the hierarchy\n",
    "  int J_1;\n",
    "  int J_2;\n",
    "  vector[N] t;\n",
    "  \n",
    "  \n",
    "  // Input of parameters of the priors\n",
    "  real hyper_a0_mu;\n",
    "  real hyper_a0_sigma;\n",
    "  \n",
    "  real hyper_k0_mu;\n",
    "  real hyper_k0_sigma;\n",
    "  \n",
    "  real hyper_a0_tau;\n",
    "  real hyper_k0_tau;\n",
    "  \n",
    "  real hyper_sigma;\n",
    "}\n",
    "\n",
    "\n",
    "generated quantities {\n",
    "  // Total number of data points \n",
    "  real area[N * J_1];\n",
    "  \n",
    "  // Priors\n",
    "  real a0 = normal_rng(hyper_a0_mu, hyper_a0_sigma);\n",
    "  real k0 = normal_rng(hyper_k0_mu, hyper_k0_sigma);\n",
    "  \n",
    "  real a0_tau = fabs(normal_rng(0, hyper_a0_tau));\n",
    "  real k0_tau = fabs(normal_rng(0, hyper_k0_tau));\n",
    "  \n",
    "  real sigma = fabs(normal_rng(0, hyper_sigma));\n",
    "  \n",
    "  // Second layer\n",
    "  real a_1[J_1]; \n",
    "  real k_1[J_1];\n",
    "  \n",
    "  for (i in 1:J_1) {\n",
    "    a_1[i] = normal_rng(a0, a0_tau);\n",
    "    k_1[i] = normal_rng(k0, k0_tau);\n",
    "    for (j in 1:N) {\n",
    "      area[(i - 1) * N + j] = normal_rng(a_1[i] * exp(k_1[i] * t[j]), sigma);\n",
    "  }\n",
    "  }\n",
    "  \n",
    "  }\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Stan code is attached above for reference, but the model is compiled from the stanalone file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile\n",
    "sm_gen = bebi103.stan.StanModel(file='hw91_model_code_pri_pred_ex.Stan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of iteration\n",
    "N_iter = 100\n",
    "T = [i for i in range (100)]\n",
    "\n",
    "\n",
    "data = dict(N=100,\n",
    "            J_1=2,\n",
    "            J_2=3,\n",
    "            t = T,\n",
    "            hyper_a0_mu=1.4,\n",
    "            hyper_a0_sigma=0.3,\n",
    "            hyper_k0_mu=0.01,\n",
    "            hyper_k0_sigma=0.002,\n",
    "            hyper_a0_tau=0.1,\n",
    "            hyper_k0_tau=0.001,\n",
    "            hyper_sigma = 0.1,\n",
    "           )\n",
    "\n",
    "# Sample\n",
    "df_pred_ex = sm_gen.sampling(data=data,\n",
    "                     algorithm='Fixed_param',\n",
    "                     warmup=0,\n",
    "                     chains=1,\n",
    "                     iter=N_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's extract the 'area' from the sample we generated and take a look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_samples_ex = bebi103.stan.extract_array(df_pred, name='area')\n",
    "\n",
    "df_samples_ex.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use the function we mentioned before to visualize the generated samples in a time-series manner. This is a good way to do prior predictive check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prior predictive check by visualzing the time-series generated data from our prior\n",
    "time = T\n",
    "\n",
    "p2 = hw92_predictive(df_samples_ex, time, name='area', plot_width=500, plot_height=400)\n",
    "\n",
    "\n",
    "bokeh.io.show(p2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trend also looks quite resonable, seems we could move on with the prior in hand for the two-level exponential model.  \n",
    "So let's move on to modeling with two-level linear model and twp-level exponential model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also have a code block to make sure once we generate sample, we could load it and do analysis without regenrating the sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If load the dumped files globally\n",
    "# Load globally\n",
    "global_load = True\n",
    "# Not load globally\n",
    "global_no_load = False\n",
    "# See if they conflict each other\n",
    "assert not (global_load and global_no_load), \"It is just not possible\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's code up the Stan code for Noncentered Linear Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_code_linear_noncentered = \"\"\"\n",
    "data {\n",
    "  // Total number of data points\n",
    "  int N;\n",
    "  \n",
    "  // Number of entries in each level of the hierarchy\n",
    "  int J_1;\n",
    "\n",
    "  //Index arrays to keep track of hierarchical structure\n",
    "  int index_1[N];\n",
    "  \n",
    "  // The measurements\n",
    "  real area[N];\n",
    "  \n",
    "  // Time\n",
    "  vector[N] t;\n",
    "}\n",
    "\n",
    "parameters {\n",
    "  // Hyperparameters level 0\n",
    "  real a;\n",
    "  real k;\n",
    "  real<lower=0> sigma;\n",
    "\n",
    "  // How hyperparameters vary\n",
    "  real<lower=0> tau_a;\n",
    "  real<lower=0> tau_k;\n",
    "\n",
    "  // Hyperparameters level 1\n",
    "  vector[J_1] a_1_tilde;\n",
    "  vector[J_1] k_1_tilde;\n",
    "}\n",
    "\n",
    "transformed parameters {\n",
    "  // Transformations for noncentered\n",
    "  vector[J_1] a_1 = a + tau_a * a_1_tilde;\n",
    "  vector[J_1] k_1 = k + tau_k * k_1_tilde;\n",
    "  vector[N] area_temp;\n",
    "  \n",
    "  for (i in 1:N) {\n",
    "    area_temp[i] = a_1[index_1[i]] + k_1[index_1[i]] * t[i];\n",
    "  }\n",
    "}\n",
    "\n",
    "model {\n",
    "  a ~ normal(1.4, 0.3);\n",
    "  k ~ normal(0.01, 0.002);\n",
    "  sigma ~ normal(0, 0.1);\n",
    "  tau_a ~ normal(0, 0.1);\n",
    "  tau_k ~ normal(0, 0.001);\n",
    "\n",
    "  a_1_tilde ~ normal(0, 1);\n",
    "  k_1_tilde ~ normal(0, 1);\n",
    "\n",
    "  area ~ normal(area_temp, sigma);\n",
    "}\n",
    "\n",
    "generated quantities {\n",
    "  vector[N] area_ppc;\n",
    "  real log_lik[N];\n",
    "  \n",
    "  // Posterior predictive check\n",
    "  for (i in 1:N) {\n",
    "    area_ppc[i] = normal_rng(area_temp[i], sigma);\n",
    "  }\n",
    "  \n",
    "  // Compute pointwise log likelihood\n",
    "  for (i in 1:N) {\n",
    "    log_lik[i] = normal_lpdf(area[i] | area_temp[i], sigma);\n",
    "  }\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Stan code is attached above for reference, but the model is compiled from the stanalone file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See if want to try to load the dumped file\n",
    "if global_load:\n",
    "    # If load globally, set it locally True\n",
    "    load_dump_file = True\n",
    "elif global_no_load:\n",
    "    # If not load globally, set it locally False\n",
    "    load_dump_file = False\n",
    "else:\n",
    "    # If global parameter is not specified, set it manually\n",
    "    load_dump_file = True\n",
    "if load_dump_file:\n",
    "    # Name the dumped file\n",
    "    dump_filename = 'linear_level1'\n",
    "    # See if the file exsits\n",
    "    if os.path.isfile(dump_filename):\n",
    "        # If it exists, load it\n",
    "        [samples_linear, sm_linear] = bebi103.stan.pickle_load_samples(dump_filename)\n",
    "    else:\n",
    "        # Or, set not to load the file and compile the model\n",
    "        print('No dumped file found, compiling the model instead')\n",
    "        load_dump_file = False\n",
    "        sm_linear = bebi103.stan.StanModel(model_code=model_code_linear_noncentered)\n",
    "# Compile the model if no dumped file is loaded\n",
    "else:\n",
    "    sm_linear = bebi103.stan.StanModel(file='hw91_model_code_linear_noncentered.Stan')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to do a test on our model, let's just use a subset of data first.  \n",
    "Let's slice out the data of the first 2 growth events of bacterium1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the input data\n",
    "# Choose a subset of data\n",
    "df_sub1 = df_bacterium1.loc[df_bacterium1['growth_event'] == 1]\n",
    "df_sub2 = df_bacterium1.loc[df_bacterium1['growth_event'] == 2]\n",
    "df_sub = pd.concat([df_sub1, df_sub2])\n",
    "\n",
    "# Take a look\n",
    "df_sub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the data into a dict for input to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make it into dict\n",
    "data = dict(N=len(df_sub),\n",
    "            J_1=2,\n",
    "            index_1=df_sub['growth_event'].values,\n",
    "            area=df_sub['area'].values,\n",
    "            t=df_sub['t'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the sampling and save the sample in a data frame for fuether analysis.  \n",
    "Also do some diagnostics on the sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If no dump file is loaded, sample\n",
    "if not load_dump_file:\n",
    "    # Sample\n",
    "    samples_linear = sm_linear.sampling(data=data, \n",
    "                                             seed=2389412, \n",
    "                                             control=dict(adapt_delta=0.99, max_treedepth=11))\n",
    "\n",
    "# Convert to data frame for easy use later\n",
    "df_linear = bebi103.stan.to_dataframe(samples_linear)\n",
    "\n",
    "bebi103.stan.check_all_diagnostics(samples_linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks great! Then we can look at the trace plot and corner plot to see what parameter estimates we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bokeh.io.show(bebi103.viz.trace_plot(samples_linear, pars=['a', 'k'], line_width=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bokeh.io.show(bebi103.viz.corner(samples_linear, pars=['a', 'k'], plot_width=300))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do the posterior predictive check using the funtion we mentioned before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = df_sub['time (min)'].values\n",
    "val = df_sub['area'].values\n",
    "df_linear_ppc = bebi103.stan.extract_array(samples_linear, name='area_ppc')\n",
    "\n",
    "p1 = hw92_predictive(df_linear_ppc, time, val, perc=[99, 75, 50, 25], name='area_ppc', plot_width=500, plot_height=400, title='Linear (two-level)')\n",
    "\n",
    "bokeh.io.show(p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Marginalized distributions of each parameter \n",
    "plots = [bebi103.viz.ecdf(df_linear[param], x_axis_label=param, plot_height=200, plot_width=250) \n",
    "                 for param in ['a', 'k']]\n",
    "bokeh.io.show(bokeh.layouts.gridplot(plots, ncols=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to save the sample in a seperated file for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(dump_filename):\n",
    "    bebi103.stan.pickle_dump_samples(fit=samples_linear, model=sm_linear, pkl_file=dump_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's move on and code up the Noncentered exponential model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the exponential model, we initially did similar things with the linear model, but we found that we need very large adaptive delta to eliminate the divergence, which we assume is because the values of $k$ in the exponential model is even smaller so that the sampler would hit a 'funnel' just due to the very small values, so we do the following modification: when we sample $k$ and parameters generated from it ($k_1$, etc.), we sample them out of distributions that are 100 times of the supposed ones, and when we compute the mean of area in the Gaussian distribution in the final layer, we divide the sampled parameters by 100. In this way, we think it would help in the funnel caused by small values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_code_exp_noncentered = \"\"\"\n",
    "data {\n",
    "  // Total number of data points\n",
    "  int N;\n",
    "  \n",
    "  // Number of entries in each level of the hierarchy\n",
    "  int J_1;\n",
    "\n",
    "  //Index arrays to keep track of hierarchical structure\n",
    "  int index_1[N];\n",
    "  \n",
    "  // The measurements\n",
    "  real area[N];\n",
    "  \n",
    "  // Time\n",
    "  vector[N] t;\n",
    "}\n",
    "\n",
    "parameters {\n",
    "  // Hyperparameters level 0\n",
    "  real a;\n",
    "  real k;\n",
    "  real<lower=0> sigma;\n",
    "\n",
    "  // How hyperparameters vary\n",
    "  real<lower=0> tau_a;\n",
    "  real<lower=0> tau_k;\n",
    "\n",
    "  // Hyperparameters level 1\n",
    "  vector[J_1] a_1_tilde;\n",
    "  vector[J_1] k_1_tilde;\n",
    "}\n",
    "\n",
    "transformed parameters {\n",
    "  // Transformations for noncentered\n",
    "  vector[J_1] a_1 = a + tau_a * a_1_tilde;\n",
    "  vector[J_1] k_1 = k + tau_k * k_1_tilde;\n",
    "  vector[N] area_temp;\n",
    "  \n",
    "  // Divide k by 100 when computing posterior\n",
    "  for (i in 1:N) {\n",
    "    area_temp[i] = a_1[index_1[i]] * exp(k_1[index_1[i]] * t[i] / 100);\n",
    "  }\n",
    "}\n",
    "\n",
    "model {\n",
    "  a ~ normal(1.4, 0.3);\n",
    "  // 100 times larger prior for k and tau_k\n",
    "  k ~ normal(1, 0.2);\n",
    "  sigma ~ normal(0, 0.1);\n",
    "  tau_a ~ normal(0, 0.1);\n",
    "  tau_k ~ normal(0, 0.1);\n",
    "\n",
    "  a_1_tilde ~ normal(0, 1);\n",
    "  k_1_tilde ~ normal(0, 1);\n",
    "\n",
    "  area ~ normal(area_temp, sigma);\n",
    "}\n",
    "\n",
    "generated quantities {\n",
    "  vector[N] area_ppc;\n",
    "  real log_lik[N];\n",
    "  \n",
    "  // Posterior predictive check\n",
    "  for (i in 1:N) {\n",
    "    area_ppc[i] = normal_rng(area_temp[i], sigma);\n",
    "  }\n",
    "  \n",
    "  // Compute pointwise log likelihood\n",
    "  for (i in 1:N) {\n",
    "    log_lik[i] = normal_lpdf(area[i] | area_temp[i], sigma);\n",
    "  }\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Stan code is attached above for reference, but the model is compiled from the stanalone file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See if want to try to load the dumped file\n",
    "if global_load:\n",
    "    # If load globally, set it locally True\n",
    "    load_dump_file = True\n",
    "elif global_no_load:\n",
    "    # If not load globally, set it locally False\n",
    "    load_dump_file = False\n",
    "else:\n",
    "    # If global parameter is not specified, set it manually\n",
    "    load_dump_file = True\n",
    "if load_dump_file:\n",
    "    # Name the dumped file\n",
    "    dump_filename = 'exp_level1'\n",
    "    # See if the file exsits\n",
    "    if os.path.isfile(dump_filename):\n",
    "        # If it exists, load it\n",
    "        [samples_exp, sm_exp] = bebi103.stan.pickle_load_samples(dump_filename)\n",
    "    else:\n",
    "        # Or, set not to load the file and compile the model\n",
    "        print('No dumped file found, compiling the model instead')\n",
    "        load_dump_file = False\n",
    "        sm_exp = bebi103.stan.StanModel(model_code=model_code_exp_noncentered)\n",
    "# Compile the model if no dumped file is loaded\n",
    "else:\n",
    "    sm_exp = bebi103.stan.StanModel(file='hw91_model_code_exp_noncentered.Stan')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to do a test on our model, let's just use a subset of data first.  \n",
    "Let's still use the data of the first 2 growth events of bacterium1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the input data\n",
    "# Choose a subset of data\n",
    "df_sub1 = df_bacterium1.loc[df_bacterium1['growth_event'] == 1]\n",
    "df_sub2 = df_bacterium1.loc[df_bacterium1['growth_event'] == 2]\n",
    "df_sub = pd.concat([df_sub1, df_sub2])\n",
    "\n",
    "# Take a look\n",
    "df_sub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the data into a dict for input to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make it into dict\n",
    "data = dict(N=len(df_sub),\n",
    "            J_1=2,\n",
    "            index_1=df_sub['growth_event'].values,\n",
    "            area=df_sub['area'].values,\n",
    "            t=df_sub['t'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the sampling and save the sample in a data frame for fuether analysis.  \n",
    "Also do some diagnostics on the sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If no dump file is loaded, sample\n",
    "if not load_dump_file:\n",
    "    # Sample\n",
    "    samples_exp = sm_exp.sampling(data=data, \n",
    "                                  seed=2389412, \n",
    "                                  control=dict(adapt_delta=0.99, max_treedepth=13))\n",
    "\n",
    "bebi103.stan.check_all_diagnostics(samples_exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks OK! Then we can look at the trace plot and corner plot to see what parameter estimates we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bokeh.io.show(bebi103.viz.trace_plot(samples_exp, pars=['a', 'k'], line_width=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bokeh.io.show(bebi103.viz.corner(samples_exp, pars=['a', 'k'], plot_width=300))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the posterior predictive check on this model.  \n",
    "Plot the linear(2-level) and exponential(2-level) posterior predictive check side by side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = df_sub['time (min)'].values\n",
    "val = df_sub['area'].values\n",
    "df_exp_ppc = bebi103.stan.extract_array(samples_exp, name='area_ppc')\n",
    "\n",
    "p2 = hw92_predictive(df_exp_ppc, time, val, perc=[99, 75, 50, 25], name='area_ppc', plot_width=500, plot_height=400, title='EXP (two-level)')\n",
    "\n",
    "bokeh.io.show(bokeh.layouts.gridplot([[p1, p2]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the sample of the two-level exponential model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(dump_filename):\n",
    "    bebi103.stan.pickle_dump_samples(fit=samples_exp, model=sm_exp, pkl_file=dump_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's Compare the two two-level models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hw91_predictive_compare(df, x, y, namex='index_1', name='area_ppc',\n",
    "                    x_axis_label=None, y_axis_label=None, title=None, plot_width=350, plot_height=225, \n",
    "                    color=color_palette[0], p=None):\n",
    "    '''Compare absolute values of the differences between sampling results and the data\n",
    "    df - MCMC sampling data frame\n",
    "    x - input variable\n",
    "    y - data\n",
    "    namex - name of the input varible in the data frame\n",
    "    name - name of the predictive results in the data frame'''\n",
    "    \n",
    "    if p is None:\n",
    "        p = bokeh.plotting.figure(plot_width=plot_width,\n",
    "                                  plot_height=plot_height,\n",
    "                                  x_axis_label=x_axis_label,\n",
    "                                  y_axis_label=y_axis_label,\n",
    "                                  title=title)\n",
    "    \n",
    "    new_df = df.copy(deep=True)\n",
    "                  \n",
    "    Nb = len(x)\n",
    "    for i in range(Nb):\n",
    "        new_df.loc[new_df[namex]== i+1, name] = np.abs(new_df.loc[new_df[namex]== i+1, name] - y[i])\n",
    "    \n",
    "    p = bebi103.viz.ecdf(new_df[name], \n",
    "                      plot_width=plot_width,\n",
    "                      plot_height=plot_height,\n",
    "                      x_axis_label=x_axis_label,\n",
    "                      y_axis_label=y_axis_label,\n",
    "                      title=title,\n",
    "                      color=color,\n",
    "                      p=p)\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc1 = hw91_predictive_compare(df_exp_ppc, time, val, name='area_ppc')\n",
    "pc1 = hw91_predictive_compare(df_linear_ppc, time, val, name='area_ppc', p=pc1, color=color_palette[1])\n",
    "\n",
    "bokeh.io.show(pc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For further model comparison, let's compute the LOO and Akaike weight of these samples: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bebi103.stan.compare({'linear': samples_linear,\n",
    "                      'exp': samples_exp},\n",
    "                     log_likelihood='log_lik',\n",
    "                     ic='loo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that the smaller LOO is, the bigger the epld is, indicating a smaller Kullback-Leibler divergence (a better model).\n",
    "So in general, the smaller LOO and the larger weight is, the closer the model is to the true generative model. \n",
    "Using this standard, we could easily tell that exponential(two-level) is better than linear(two-level).  \n",
    "\n",
    "Now let's move on and consider the fact that we have 2 bacteriums. So let's add one level to the hierachical model considering the variation withn different bacteriums."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Three levels hierachical model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When considering the bacteriaum variation, we basically add top layer. The prior predictive check here is very similar to the two-level model, so we will just skip the prior predictive check in this part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's code up our model for three-level linear model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_code_linear_2 = \"\"\"\n",
    "data {\n",
    "  // Total number of data points\n",
    "  int N;\n",
    "  \n",
    "  // Number of entries in each level of the hierarchy\n",
    "  int J_1;\n",
    "  int J_2;\n",
    "  \n",
    "  //Index arrays to keep track of hierarchical structure\n",
    "  int index_1[J_2];\n",
    "  int index_2[N];\n",
    "  \n",
    "  // The measurements\n",
    "  real area[N];\n",
    "  \n",
    "  // Time\n",
    "  vector[N] t;\n",
    "}\n",
    "\n",
    "parameters {\n",
    "  // Hyperparameters level 0\n",
    "  real a;\n",
    "  real k;\n",
    "  real<lower=0> sigma;\n",
    "\n",
    "  // How hyperparameters vary\n",
    "  real<lower=0> tau_a;\n",
    "  real<lower=0> tau_k;\n",
    "\n",
    "  // Hyperparameters level 1\n",
    "  vector[J_1] a_1_tilde;\n",
    "  vector[J_1] k_1_tilde;\n",
    "  \n",
    "  // Hyperparameters level 2\n",
    "  vector[J_2] a_2_tilde;\n",
    "  vector[J_2] k_2_tilde;\n",
    "}\n",
    "\n",
    "transformed parameters {\n",
    "  // Transformations for noncentered\n",
    "  vector[J_1] a_1 = a + tau_a * a_1_tilde;\n",
    "  vector[J_1] k_1 = k + tau_k * k_1_tilde;\n",
    "  \n",
    "  vector[J_2] a_2 = a_1[index_1] + tau_a * a_2_tilde;\n",
    "  vector[J_2] k_2 = k_1[index_1] + tau_k * k_2_tilde;\n",
    "  \n",
    "  vector[N] area_temp;\n",
    "  \n",
    "  for (i in 1:N) {\n",
    "    area_temp[i] = a_2[index_2[i]] + k_2[index_2[i]] * t[i];\n",
    "  }\n",
    "}\n",
    "\n",
    "model {\n",
    "  a ~ normal(1.4, 0.3);\n",
    "  k ~ normal(0.01, 0.002);\n",
    "  sigma ~ normal(0, 0.1);\n",
    "  tau_a ~ normal(0, 0.1);\n",
    "  tau_k ~ normal(0, 0.001);\n",
    "\n",
    "  a_1_tilde ~ normal(0, 1);\n",
    "  k_1_tilde ~ normal(0, 1);\n",
    "  \n",
    "  a_2_tilde ~ normal(0, 1);\n",
    "  k_2_tilde ~ normal(0, 1);\n",
    "\n",
    "  area ~ normal(area_temp, sigma);\n",
    "}\n",
    "\n",
    "generated quantities {\n",
    "  vector[N] area_ppc;\n",
    "  real log_lik[N];\n",
    "  \n",
    "  // Posterior predictive check\n",
    "  for (i in 1:N) {\n",
    "    area_ppc[i] = normal_rng(area_temp[i], sigma);\n",
    "  }\n",
    "  \n",
    "  // Compute pointwise log likelihood\n",
    "  for (i in 1:N) {\n",
    "    log_lik[i] = normal_lpdf(area[i] | area_temp[i], sigma);\n",
    "  }\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Stan code is attached above for reference, but the model is compiled from the stanalone file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See if want to try to load the dumped file\n",
    "if global_load:\n",
    "    # If load globally, set it locally True\n",
    "    load_dump_file = True\n",
    "elif global_no_load:\n",
    "    # If not load globally, set it locally False\n",
    "    load_dump_file = False\n",
    "else:\n",
    "    # If global parameter is not specified, set it manually\n",
    "    load_dump_file = True\n",
    "if load_dump_file:\n",
    "    # Name the dumped file\n",
    "    dump_filename = 'linear_level2'\n",
    "    # See if the file exsits\n",
    "    if os.path.isfile(dump_filename):\n",
    "        # If it exists, load it\n",
    "        [samples_linear_2, sm_linear_2] = bebi103.stan.pickle_load_samples(dump_filename)\n",
    "    else:\n",
    "        # Or, set not to load the file and compile the model\n",
    "        print('No dumped file found, compiling the model instead')\n",
    "        load_dump_file = False\n",
    "        sm_linear_2 = bebi103.stan.StanModel(model_code=model_code_linear_2)\n",
    "# Compile the model if no dumped file is loaded\n",
    "else:\n",
    "    sm_linear_2 = bebi103.stan.StanModel(fiel='hw91_model_code_linear_2.Stan')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to test a model, we slice out a subset of the data including the first 3 growth events for both bacterium 1 and 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the input data\n",
    "df_sub1 = df.loc[(df['growth_event'] == 1) & (df['bacterium'] == 1)]\n",
    "df_sub2 = df.loc[(df['growth_event'] == 2) & (df['bacterium'] == 1)]\n",
    "df_sub3 = df.loc[(df['growth_event'] == 3) & (df['bacterium'] == 2)]\n",
    "df_sub = pd.concat([df_sub1, df_sub2])\n",
    "df_sub = pd.concat([df_sub, df_sub3])\n",
    "# Rename for convenience\n",
    "df_sub = df_sub.rename(columns={'area (sq um)': 'area'})\n",
    "\n",
    "df_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the data Into dict\n",
    "data, df_part = bebi103.stan.df_to_datadict_hier(df_sub,\n",
    "                                           level_cols=['bacterium', 'growth_event'],\n",
    "                                           data_cols=['area', 't'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the sampling and save the sample in a data frame for fuether analysis.  \n",
    "Also do some diagnostics on the sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If no dump file is loaded, sample\n",
    "if not load_dump_file:\n",
    "    # Sample\n",
    "    samples_linear_2 = sm_linear_2.sampling(data=data, \n",
    "                                            seed=2389412, \n",
    "                                            control=dict(adapt_delta=0.99, max_treedepth=13))\n",
    "\n",
    "bebi103.stan.check_all_diagnostics(samples_linear_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks great! Then we can look at the trace plot and corner plot to see what parameter estimates we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bokeh.io.show(bebi103.viz.trace_plot(samples_linear_2, pars=['a', 'k'], line_width=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bokeh.io.show(bebi103.viz.corner(samples_linear_2, pars=['a', 'k'], plot_width=300))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the posterior predictive check on this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = df_sub['time (min)'].values\n",
    "val = df_sub['area'].values\n",
    "df_lin2_ppc = bebi103.stan.extract_array(samples_linear_2, name='area_ppc')\n",
    "\n",
    "p3 = hw92_predictive(df_lin2_ppc, time, val, perc=[99, 75, 50, 25], name='area_ppc', plot_width=500, plot_height=400, title='Linear (Three-level)', baseline=0)\n",
    "\n",
    "bokeh.io.show(p3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the sample for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(dump_filename):\n",
    "    bebi103.stan.pickle_dump_samples(fit=samples_linear_2, model=sm_linear_2, pkl_file=dump_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's move on and code up the 3-leevel exponential model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_code_exp_2 = \"\"\"\n",
    "data {\n",
    "  // Total number of data points\n",
    "  int N;\n",
    "  \n",
    "  // Number of entries in each level of the hierarchy\n",
    "  int J_1;\n",
    "  int J_2;\n",
    "  \n",
    "  //Index arrays to keep track of hierarchical structure\n",
    "  int index_1[J_2];\n",
    "  int index_2[N];\n",
    "  \n",
    "  // The measurements\n",
    "  real area[N];\n",
    "  \n",
    "  // Time\n",
    "  vector[N] t;\n",
    "}\n",
    "\n",
    "parameters {\n",
    "  // Hyperparameters level 0\n",
    "  real a;\n",
    "  real k;\n",
    "  real<lower=0> sigma;\n",
    "\n",
    "  // How hyperparameters vary\n",
    "  real<lower=0> tau_a;\n",
    "  real<lower=0> tau_k;\n",
    "\n",
    "  // Hyperparameters level 1\n",
    "  vector[J_1] a_1_tilde;\n",
    "  vector[J_1] k_1_tilde;\n",
    "  \n",
    "  // Hyperparameters level 2\n",
    "  vector[J_2] a_2_tilde;\n",
    "  vector[J_2] k_2_tilde;\n",
    "}\n",
    "\n",
    "transformed parameters {\n",
    "  // Transformations for noncentered\n",
    "  vector[J_1] a_1 = a + tau_a * a_1_tilde;\n",
    "  vector[J_1] k_1 = k + tau_k * k_1_tilde;\n",
    "  \n",
    "  vector[J_2] a_2 = a_1[index_1] + tau_a * a_2_tilde;\n",
    "  vector[J_2] k_2 = k_1[index_1] + tau_k * k_2_tilde;\n",
    "  \n",
    "  vector[N] area_temp;\n",
    "  \n",
    "  // Divide k by 100 when computing posterior\n",
    "  for (i in 1:N) {\n",
    "    area_temp[i] = a_2[index_2[i]] * exp(k_2[index_2[i]] * t[i] / 100);\n",
    "  }\n",
    "}\n",
    "\n",
    "model {\n",
    "  a ~ normal(1.4, 0.3);\n",
    "  // 100 times large prior for k and tau_k\n",
    "  k ~ normal(1, 0.2);\n",
    "  sigma ~ normal(0, 0.1);\n",
    "  tau_a ~ normal(0, 0.1);\n",
    "  tau_k ~ normal(0, 0.1);\n",
    "\n",
    "  a_1_tilde ~ normal(0, 1);\n",
    "  k_1_tilde ~ normal(0, 1);\n",
    "  \n",
    "  a_2_tilde ~ normal(0, 1);\n",
    "  k_2_tilde ~ normal(0, 1);\n",
    "\n",
    "  area ~ normal(area_temp, sigma);\n",
    "}\n",
    "\n",
    "generated quantities {\n",
    "  vector[N] area_ppc;\n",
    "  real log_lik[N];\n",
    "  \n",
    "  // Posterior predictive check\n",
    "  for (i in 1:N) {\n",
    "    area_ppc[i] = normal_rng(area_temp[i], sigma);\n",
    "  }\n",
    "  \n",
    "  // Compute pointwise log likelihood\n",
    "  for (i in 1:N) {\n",
    "    log_lik[i] = normal_lpdf(area[i] | area_temp[i], sigma);\n",
    "  }\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Stan code is attached above for reference, but the model is compiled from the stanalone file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See if want to try to load the dumped file\n",
    "if global_load:\n",
    "    # If load globally, set it locally True\n",
    "    load_dump_file = True\n",
    "elif global_no_load:\n",
    "    # If not load globally, set it locally False\n",
    "    load_dump_file = False\n",
    "else:\n",
    "    # If global parameter is not specified, set it manually\n",
    "    load_dump_file = False\n",
    "if load_dump_file:\n",
    "    # Name the dumped file\n",
    "    dump_filename = 'exp_level2'\n",
    "    # See if the file exsits\n",
    "    if os.path.isfile(dump_filename):\n",
    "        # If it exists, load it\n",
    "        [samples_exp_2, sm_exp_2] = bebi103.stan.pickle_load_samples(dump_filename)\n",
    "    else:\n",
    "        # Or, set not to load the file and compile the model\n",
    "        print('No dumped file found, compiling the model instead')\n",
    "        load_dump_file = False\n",
    "        sm_exp_2 = bebi103.stan.StanModel(model_code=model_code_exp_2)\n",
    "# Compile the model if no dumped file is loaded\n",
    "else:\n",
    "    sm_exp_2 = bebi103.stan.StanModel(file='hw91_model_code_exp_2.Stan')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to test a model, we slice out a subset of the data including the first 3 growth events for both bacterium 1 and 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the input data\n",
    "df_sub1 = df.loc[(df['growth_event'] == 1) & (df['bacterium'] == 1)]\n",
    "df_sub2 = df.loc[(df['growth_event'] == 2) & (df['bacterium'] == 1)]\n",
    "df_sub3 = df.loc[(df['growth_event'] == 3) & (df['bacterium'] == 2)]\n",
    "df_sub = pd.concat([df_sub1, df_sub2])\n",
    "df_sub = pd.concat([df_sub, df_sub3])\n",
    "# Rename for convenience\n",
    "df_sub = df_sub.rename(columns={'area (sq um)': 'area'})\n",
    "\n",
    "df_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Into dict\n",
    "data, df_part = bebi103.stan.df_to_datadict_hier(df_sub,\n",
    "                                           level_cols=['bacterium', 'growth_event'],\n",
    "                                           data_cols=['area', 't'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the sampling and save the sample in a data frame for fuether analysis.  \n",
    "Also do some diagnostics on the sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If no dump file is loaded, sample\n",
    "if not load_dump_file:\n",
    "    # Sample\n",
    "    samples_exp_2 = sm_exp_2.sampling(data=data, \n",
    "                                  seed=2389412, \n",
    "                                  control=dict(adapt_delta=0.99, max_treedepth=13))\n",
    "\n",
    "bebi103.stan.check_all_diagnostics(samples_exp_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks great! Then we can look at the trace plot and corner plot to see what parameter estimates we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bokeh.io.show(bebi103.viz.trace_plot(samples_exp_2, pars=['a', 'k'], line_width=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bokeh.io.show(bebi103.viz.corner(samples_exp_2, pars=['a', 'k']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the posterior predictive check on this model.  \n",
    "Plot the linear(3-level) and exponential(3-level) posterior predictive check side by side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = df_sub['time (min)'].values\n",
    "val = df_sub['area'].values\n",
    "df_exp2_ppc = bebi103.stan.extract_array(samples_exp_2, name='area_ppc')\n",
    "\n",
    "p4 = hw92_predictive(df_exp2_ppc, time, val, perc=[99, 75, 50, 25], name='area_ppc', plot_width=500, plot_height=400, title='EXP (Three-level)')\n",
    "\n",
    "bokeh.io.show(bokeh.layouts.gridplot([[p3, p4]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the sample of the three-level exponential model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(dump_filename):\n",
    "    bebi103.stan.pickle_dump_samples(fit=samples_exp_2, model=sm_exp_2, pkl_file=dump_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's Compare the two three-level models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc2 = hw91_predictive_compare(df_exp2_ppc, time, val, name='area_ppc')\n",
    "pc2 = hw91_predictive_compare(df_lin2_ppc, time, val, name='area_ppc', p=pc2, color=color_palette[1])\n",
    "\n",
    "bokeh.io.show(bokeh.layouts.gridplot([[pc1, pc2]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For further model comparison, let's compute the LOO and Akaike weight of these samples: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bebi103.stan.compare({'linear': samples_linear_2,\n",
    "                      'exp': samples_exp_2},\n",
    "                     log_likelihood='log_lik',\n",
    "                     ic='loo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that the smaller LOO is, the bigger the epld is, indicating a smaller Kullback-Leibler divergence (a better model).\n",
    "So in general, the smaller LOO and the larger weight is, the closer the model is to the true generative model. \n",
    "Using this standard, we could easily tell that exponential(three-level) is better than linear(three-level) when dealing this small subset of the data.  \n",
    "\n",
    "Now let's move on and analyze the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the input data for the full data set\n",
    "data, df_part = bebi103.stan.df_to_datadict_hier(df,\n",
    "                                           level_cols=['bacterium', 'growth_event'],\n",
    "                                           data_cols=['area', 't'])\n",
    "\n",
    "# Take a look\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using 'bebi103.stan.df_to_datadict_hier', sometime we find that the input data is not in right order, which cause great trouble in further analysis and plotting, To prevent that, we decide to check the order of the input data before putting it into the sampler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bacterium 1\n",
    "p = bokeh.plotting.figure(height=300)\n",
    "len_data = len(df.loc[df['bacterium']==1, 'time (min)'].values)\n",
    "p.line(df.loc[df['bacterium']==1, 'time (min)'].values, df.loc[df['bacterium']==1, 'area'].values - data['area'][:len_data])\n",
    "bokeh.io.show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bacterium 2\n",
    "p = bokeh.plotting.figure(height=300)\n",
    "len_data = len(df.loc[df['bacterium']==1, 'time (min)'].values)\n",
    "p.line(df.loc[df['bacterium']==2, 'time (min)'].values, df.loc[df['bacterium']==2, 'area'].values - data['area'][len_data:], color=color_palette[1])\n",
    "bokeh.io.show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The order of the input data is right! Let's put them into sampler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See if want to try to load the dumped file\n",
    "if global_load:\n",
    "    # If load globally, set it locally True\n",
    "    load_dump_file = True\n",
    "elif global_no_load:\n",
    "    # If not load globally, set it locally False\n",
    "    load_dump_file = False\n",
    "else:\n",
    "    # If global parameter is not specified, set it manually\n",
    "    load_dump_file = True\n",
    "if load_dump_file:\n",
    "    # Name the dumped file\n",
    "    dump_filename = 'linear_level2_full'\n",
    "    # See if the file exsits\n",
    "    if os.path.isfile(dump_filename):\n",
    "        # If it exists, load it\n",
    "        [samples_linear_2_full, sm_linear_2] = bebi103.stan.pickle_load_samples(dump_filename)\n",
    "    else:\n",
    "        # Or, set not to load the file and compile the model\n",
    "        print('No dumped file found, compiling the model instead')\n",
    "        load_dump_file = False\n",
    "        sm_linear_2 = bebi103.stan.StanModel(model_code=model_code_linear_2)\n",
    "# Compile the model if no dumped file is loaded\n",
    "else:\n",
    "    sm_linear_2 = bebi103.stan.StanModel(model_code=model_code_linear_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sampling (3-level linear model):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If no dump file is loaded, sample\n",
    "if not load_dump_file:\n",
    "    # Sample\n",
    "    samples_linear_2_full = sm_linear_2.sampling(data=data, \n",
    "                                                 seed=2389412, \n",
    "                                                 control=dict(adapt_delta=0.99, max_treedepth=15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnostic\n",
    "bebi103.stan.check_all_diagnostics(samples_linear_2_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dianostic looks great!  \n",
    "Let's save the Sample from 3-level linear model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(dump_filename):\n",
    "    bebi103.stan.pickle_dump_samples(fit=samples_linear_2_full, model=sm_linear_2, pkl_file=dump_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See if want to try to load the dumped file\n",
    "if global_load:\n",
    "    # If load globally, set it locally True\n",
    "    load_dump_file = True\n",
    "elif global_no_load:\n",
    "    # If not load globally, set it locally False\n",
    "    load_dump_file = False\n",
    "else:\n",
    "    # If global parameter is not specified, set it manually\n",
    "    load_dump_file = True\n",
    "if load_dump_file:\n",
    "    # Name the dumped file\n",
    "    dump_filename = 'exp_level2_full'\n",
    "    # See if the file exsits\n",
    "    if os.path.isfile(dump_filename):\n",
    "        # If it exists, load it\n",
    "        [samples_exp_2_full, sm_exp_2] = bebi103.stan.pickle_load_samples(dump_filename)\n",
    "    else:\n",
    "        # Or, set not to load the file and compile the model\n",
    "        print('No dumped file found, compiling the model instead')\n",
    "        load_dump_file = False\n",
    "        sm_exp_2 = bebi103.stan.StanModel(model_code=model_code_exp_2)\n",
    "# Compile the model if no dumped file is loaded\n",
    "else:\n",
    "    sm_exp_2 = bebi103.stan.StanModel(model_code=model_code_exp_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sampling (3-level exponential model):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If no dump file is loaded, sample\n",
    "if not load_dump_file:\n",
    "    # Sample\n",
    "    samples_exp_2_full = sm_exp_2.sampling(data=data, \n",
    "                                           seed=2389412, \n",
    "                                           control=dict(adapt_delta=0.99, max_treedepth=15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnostic\n",
    "bebi103.stan.check_all_diagnostics(samples_exp_2_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dianostic looks great!  \n",
    "Let's save the Sample from 3-level exponential model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(dump_filename):\n",
    "    bebi103.stan.pickle_dump_samples(fit=samples_exp_2_full, model=sm_exp_2, pkl_file=dump_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the parameter of the 3-level linear model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bokeh.io.show(bebi103.viz.corner(samples_linear_2_full, pars=['a', 'k'], plot_width=300))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the predictive data. But when we try to do the plotting, we realize if we plot the 2 bacteria together, it will cause a huge confusion, because they will all start from time = 0, and they would overlay with each other in the plot. So we we decided to plot Bacterium1 and Bacterium2 seperately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the predictive data from 3-level linear model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = df['time (min)'].values\n",
    "time1 = df.loc[df['bacterium']==1, 'time (min)'].values\n",
    "time2 = df.loc[df['bacterium']==2, 'time (min)'].values\n",
    "val = df['area'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_linear_2_ppc_full = bebi103.stan.extract_array(samples_linear_2_full, name='area_ppc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf1 = hw92_predictive(df_linear_2_ppc_full, time1, val, perc=[99, 75, 50, 25], name='area_ppc', plot_width=2000, plot_height=1000, title='Linear (Three-level), full data set, bacterium 1')\n",
    "pf2 = hw92_predictive(df_linear_2_ppc_full, time2, val, perc=[99, 75, 50, 25], name='area_ppc', plot_width=2000, plot_height=1000, title='Linear (Three-level), full data set, bacterium 2', baseline=len(time1))\n",
    "\n",
    "bokeh.io.show(bokeh.layouts.gridplot([[pf1], [pf2]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the parameter of the 3-level exponential model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bokeh.io.show(bebi103.viz.corner(samples_exp_2_full, pars=['a', 'k'], plot_width=300))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the predictive data from 3-level linear model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exp_2_ppc_full = bebi103.stan.extract_array(samples_exp_2_full, name='area_ppc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf3 = hw92_predictive(df_exp_2_ppc_full, time1, val, perc=[99, 75, 50, 25], name='area_ppc', plot_width=2000, plot_height=1000, title='EXP (Three-level), full data set, bacterium 1')\n",
    "pf4 = hw92_predictive(df_exp_2_ppc_full, time2, val, perc=[99, 75, 50, 25], name='area_ppc', plot_width=2000, plot_height=1000, title='EXP (Three-level), full data set, bacterium 2', baseline=len(time1))\n",
    "\n",
    "bokeh.io.show(bokeh.layouts.gridplot([[pf3], [pf4]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare these 2 models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bebi103.stan.compare({'linear': samples_linear_2_full,\n",
    "                      'exp': samples_exp_2_full},\n",
    "                     log_likelihood='log_lik',\n",
    "                     ic='loo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc3 = hw91_predictive_compare(df_exp_2_ppc_full, time, val, name='area_ppc')\n",
    "pc3 = hw91_predictive_compare(df_linear_2_ppc_full, time, val, name='area_ppc', p=pc3, color=color_palette[1])\n",
    "\n",
    "bokeh.io.show(bokeh.layouts.gridplot([[pc3]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%watermark -v -p numpy,scipy,bokeh,jupyterlab"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
