{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import altair as alt\n",
    "import bebi103\n",
    "import altair_catplot as altcat\n",
    "import scipy.special as sp\n",
    "import numba\n",
    "\n",
    "import bokeh.io\n",
    "import bokeh.plotting\n",
    "bokeh.io.output_notebook()\n",
    "color_palette=['#4e79a7', '#f28e2b', '#e15759', '#76b7b2', '#59a14f', '#edc948', '#b07aa1', '#ff9da7', '#9c755f', '#bab0ac']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attribution: Zhiyang did the problem and used the sampler Maddie coded up in hw7.1; the whole group discuss together about the way to do the thrid part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a)**\n",
    "\n",
    "We use the model built in homework 6.1 where we have a prior of Beta distribution for $\\theta$ and the likelihood of binomial distribution for the number of reversals. To practice and make sure the Stan sampling function is working well, we conduct the prior predictive check first using Stan. The Stan codes would be both in the attached standalones file hw72_pri_pred.stan and shown below for reference, but we always complie the standalone ones in this homework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hw72_pri_pred = \"\"\"\n",
    "data {\n",
    "  int N;  \n",
    "  real a;\n",
    "  real b;\n",
    "  int Nt;\n",
    "}\n",
    "\n",
    "generated quantities{\n",
    "  real n[N];\n",
    "  real theta = beta_rng(a, b);\n",
    "  \n",
    "  for (i in 1:N) {\n",
    "    n[i] = binomial_rng(Nt, theta);\n",
    "  }\n",
    "}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complie from the standalone file\n",
    "sm_gen = bebi103.stan.StanModel(file='hw72_pri_pred.stan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mcmc_theta(sm_gen, alpha, beta, Num_t, Num=500, N_iter=1000):\n",
    "    '''prior predictive check using Stan'''\n",
    "    # Pass parameters to Stan data\n",
    "    data = dict(N=Num,\n",
    "               a = alpha,\n",
    "               b = beta,\n",
    "               Nt = Num_t)\n",
    "    # Return data type that can be used in the predictive_ecdf directly\n",
    "    return sm_gen.sampling(data=data,\n",
    "                           algorithm='Fixed_param',\n",
    "                           warmup=0,\n",
    "                           chains=1,\n",
    "                           iter=N_iter)\n",
    "\n",
    "# Use the parameters in HW6.1\n",
    "alpha, beta, Nt = 0.2, 8, 126\n",
    "\n",
    "# Show the results from prior predictive check using predictive_ecdf function\n",
    "bokeh.io.show(\n",
    "    bebi103.viz.predictive_ecdf(mcmc_theta(sm_gen, alpha, beta, Nt), \n",
    "                                'n', \n",
    "                                x_axis_label='WT, number of reversals'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the same thing for other two stains, ASH here\n",
    "alpha, beta, Nt = 5.5, 18., 124\n",
    "\n",
    "bokeh.io.show(\n",
    "    bebi103.viz.predictive_ecdf(mcmc_theta(sm_gen, alpha, beta, Nt), \n",
    "                                'n', \n",
    "                                x_axis_label='ASH, number of reversals'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AVA\n",
    "alpha, beta, Nt = 8., 3., 124\n",
    "\n",
    "bokeh.io.show(\n",
    "    bebi103.viz.predictive_ecdf(mcmc_theta(sm_gen, alpha, beta, Nt), \n",
    "                                'n', \n",
    "                                x_axis_label='AVA, number of reversals'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks pretty much the same with ones we've got from HW6.2, so we proceed and code up the stan code for the whole model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hw72_pri_gen = \"\"\"\n",
    "data { \n",
    "  real a;\n",
    "  real b;\n",
    "  int Nt;\n",
    "  int n;\n",
    "}\n",
    "\n",
    "\n",
    "parameters {\n",
    "  real<lower=0, upper=1> theta;\n",
    "}\n",
    "\n",
    "\n",
    "model {\n",
    "  // Priors\n",
    "  theta ~ beta(a, b);\n",
    "\n",
    "  // Likelihood\n",
    "  n ~ binomial(Nt, theta);\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_gen_pri = bebi103.stan.StanModel(file='hw72_pri_gen.stan')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to prior predictive check, we have a function to pass parameters and draw samples out of the corresponding posteriors. The only difference here is that the function returns transformed dataframe for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mcmc_theta_sampling(sm_gen, params , N_iter=100000):\n",
    "    '''Sample out of the posterior'''\n",
    "    # Pass parameters\n",
    "    alpha, beta, Num_t, num = params\n",
    "    \n",
    "    data = dict(a=alpha,\n",
    "                b=beta,\n",
    "                Nt=Num_t,\n",
    "                n=num)\n",
    "    \n",
    "    samples = sm_gen.sampling(data=data, iter=N_iter)\n",
    "    \n",
    "    return bebi103.stan.to_dataframe(samples, diagnostics=False, inc_warmup=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass parameters as indicated in the function: \n",
    "# two parameters for Beta distribution, number of trial and number of reversals.\n",
    "params = [0.2, 8., 126, 13]\n",
    "\n",
    "# Sample out of the posterior\n",
    "df_mcmc = mcmc_theta_sampling(sm_gen_pri, params, 100000)\n",
    "\n",
    "# Specify the strain in the dataframe\n",
    "df_mcmc['Strain'] = 'WT'\n",
    "\n",
    "# Take a look\n",
    "df_mcmc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that we have the samples drawn from the posterior stored in the dataframe, so we can basically have a loop to do all those things to three strains we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of iteration we do\n",
    "N_iter = 10000\n",
    "\n",
    "# Name of the stains for plotting\n",
    "strain = ['ASH','AVA','WT']\n",
    "\n",
    "# Corresponding paramters\n",
    "params = [[5.5, 18., 124, 39], \n",
    "          [8., 3., 124, 91],\n",
    "          [0.2, 8., 126, 13]]\n",
    "\n",
    "# Initialize the data frame\n",
    "df_mcmc = pd.DataFrame()\n",
    "\n",
    "# Initialize histogram plot\n",
    "p1 = bokeh.plotting.figure(width=400, height=300, title='Stan sampler')\n",
    "\n",
    "\n",
    "for i, strain_name in enumerate(strain):\n",
    "    # Sample out of each strain's posterior\n",
    "    temp = mcmc_theta_sampling(sm_gen_pri, params[i], N_iter)\n",
    "    temp['Strain'] = strain_name\n",
    "    # Plot the samples' histogram for each\n",
    "    p1 = bebi103.viz.histogram(temp['theta'],\n",
    "                               p=p1,\n",
    "                               bins=35,\n",
    "                               line_width=2,\n",
    "                               density=True,\n",
    "                               x_axis_label='theta',\n",
    "                               y_axis_label='g(theta|y)',\n",
    "                               color = color_palette[i])\n",
    "    # Record the samples in data frame for ecdf\n",
    "    df_mcmc = pd.concat([df_mcmc, temp])\n",
    "\n",
    "# Reset index    \n",
    "df_mcmc = df_mcmc.reset_index(drop=True)\n",
    "\n",
    "# Plot ECDF collection\n",
    "p2 = bebi103.viz.ecdf_collection(data=df_mcmc, \n",
    "                                cats='Strain',\n",
    "                                val='theta',\n",
    "                                formal=True,\n",
    "                                line_width=2,\n",
    "                                plot_width=600,\n",
    "                                plot_height=300)\n",
    "\n",
    "bokeh.io.show(bokeh.layouts.gridplot([p1, p2], ncols=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks good and similar to what we've got from HW6.2. We may use this as a reference for our own sampler below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)**\n",
    "\n",
    "We basically move all the functions from HW7.1 here, with slight modifications. The step and sample functions are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mh_step(x, logpost, logpost_current, sigma, args=()):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : ndarray, shape (n_variables,)\n",
    "        The present location of the walker in parameter space.\n",
    "    logpost : function\n",
    "        The function to compute the log posterior. It has call\n",
    "        signature `logpost(x, *args)`.\n",
    "    logpost_current : float\n",
    "        The current value of the log posterior.\n",
    "    sigma : ndarray, shape (n_variables, )\n",
    "        The standard deviations for the proposal distribution.\n",
    "    args : tuple\n",
    "        Additional arguments passed to `logpost()` function.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    output : ndarray, shape (n_variables,)\n",
    "        The position of the walker after the Metropolis-Hastings\n",
    "        step. If no step is taken, returns the inputted `x`.\n",
    "    \"\"\"\n",
    "    # Get next step\n",
    "    x_next = np.random.normal(x, sigma)\n",
    "\n",
    "    # Calculate r\n",
    "    theta_p = np.exp(logpost(x_next, *args))\n",
    "    theta_i = np.exp(logpost_current)\n",
    "    r = theta_p / theta_i\n",
    "#     print(r)\n",
    "    \n",
    "    # Choose to accept or reject step    \n",
    "    p = np.random.uniform(0, 1)\n",
    "    if p <= r:\n",
    "        return x_next, 1\n",
    "    else:\n",
    "        return x, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mh_sample(logpost, x0, sigma, args=(), n_burn=1000, n_steps=1000,\n",
    "              variable_names=None):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    logpost : function\n",
    "        The function to compute the log posterior. It has call\n",
    "        signature `logpost(x, *args)`.\n",
    "    x0 : ndarray, shape (n_variables,)\n",
    "        The starting location of a walker in parameter space.\n",
    "    sigma : ndarray, shape (n_variables, )\n",
    "        The standard deviations for the proposal distribution.\n",
    "    args : tuple\n",
    "        Additional arguments passed to `logpost()` function.\n",
    "    n_burn : int, default 1000\n",
    "        Number of burn-in steps.\n",
    "    n_steps : int, default 1000\n",
    "        Number of steps to take after burn-in.\n",
    "    variable_names : list, length n_variables\n",
    "        List of names of variables. If None, then variable names\n",
    "        are sequential integers.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    output : DataFrame\n",
    "        The first `n_variables` columns contain the samples.\n",
    "        Additionally, column 'lnprob' has the log posterior value\n",
    "        at each sample.\n",
    "    \"\"\"\n",
    "    x = x0\n",
    "    n_variables = []\n",
    "    lnprob = []\n",
    "    n_accept = 0\n",
    "\n",
    "    for i in range(n_burn):\n",
    "        logpost_current = logpost(x, *args)\n",
    "        x, accept = mh_step(x, logpost, logpost_current, sigma, args=args)\n",
    "\n",
    "    # Draw samples\n",
    "    for i in range(n_steps):\n",
    "        n_variables.append(x)\n",
    "        lnprob.append(logpost_current)\n",
    "\n",
    "        logpost_current = logpost(x, *args)\n",
    "        x, accept = mh_step(x, logpost, logpost_current, sigma, args=args)\n",
    "        n_accept += accept\n",
    "    \n",
    "    accept_rate = n_accept / n_steps\n",
    "    \n",
    "    if accept_rate < 0.2 or accept_rate > 0.5:\n",
    "        return pd.DataFrame(), accept_rate\n",
    "    \n",
    "    else:\n",
    "        df = pd.DataFrame(data=n_variables, columns=['theta'])\n",
    "        df['lnprob'] = lnprob\n",
    "        return df, accept_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The major difference is the posterior of the distribution, here we just explicitly code up the log posterior for our model as the one in HW6.1. Also, to avoid invalid value, the function would return negative infinty once the $\\theta$ is not within 0 and 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_test_distribution(theta, alpha, beta, N, n):\n",
    "    \"\"\"\n",
    "    Unnormalized log posterior of a multivariate Gaussian.\n",
    "    \"\"\"\n",
    "    if theta <= 0 or theta >= 1:\n",
    "        return -np.inf\n",
    "    else:\n",
    "        return sp.loggamma(N + 1) - sp.loggamma(n + 1) - sp.loggamma(N - n + 1) + \\\n",
    "               (n + alpha - 1) * np.log(theta) + (N - n + beta - 1) * np.log(1 - theta)\\\n",
    "               + sp.loggamma(alpha + beta) - sp.loggamma(alpha) - sp.loggamma(beta)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same sigma tuning function is used here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_sigma(accept_rate, sigma):\n",
    "    if accept_rate < 0.001:\n",
    "        return sigma * 0.1\n",
    "    elif accept_rate < 0.05:\n",
    "        return sigma * 0.5\n",
    "    elif accept_rate < 0.2:\n",
    "        return sigma * 0.9\n",
    "        return sigma * 0.975\n",
    "    elif accept_rate > 0.5:\n",
    "        return sigma * 1.1\n",
    "    elif accept_rate > 0.75:\n",
    "        return sigma * 2\n",
    "    elif accept_rate > 0.95:\n",
    "        return sigma * 10\n",
    "    else:\n",
    "        return sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure everything goes well, we sample the WT posterior first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of iteration\n",
    "N_iter =10000\n",
    "\n",
    "# Give the initial step and sigma\n",
    "x0 = 0.2\n",
    "sigma = 1\n",
    "\n",
    "# Pass parameters as the way it is unpacked:\n",
    "# alpha, beta, number of trials, number of reversals\n",
    "pa = [0.2, 8., 126, 13]\n",
    "\n",
    "# Initialize the data frame\n",
    "df_samples = pd.DataFrame()\n",
    "\n",
    "# Take samples\n",
    "df_samples, accept_rate = mh_sample(log_test_distribution, \n",
    "                                    x0, \n",
    "                                    sigma, \n",
    "                                    args=pa, \n",
    "                                    n_burn=1000, \n",
    "                                    n_steps=N_iter, \n",
    "                                    variable_names=None)\n",
    "while len(df_samples) == 0:\n",
    "    sigma = tune_sigma(accept_rate, sigma)\n",
    "    df_samples, accept_rate = mh_sample(log_test_distribution, \n",
    "                                        x0, \n",
    "                                        sigma, \n",
    "                                        args=pa, \n",
    "                                        n_burn=1000, \n",
    "                                        n_steps=N_iter, variable_names=None)\n",
    "\n",
    "# Take a look at ECDF for WT\n",
    "bokeh.io.show(bebi103.viz.ecdf(df_samples['theta']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ECDF looks good, so we proceed and have a function to do this over all the strains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hw7_sampling(x0, sigma, params, log_test_distribution, num_burn, N_iter=10000, variable_names=None):\n",
    "\n",
    "        # Take samples\n",
    "    df_samples, accept_rate = mh_sample(log_test_distribution, \n",
    "                                        x0, \n",
    "                                        sigma, \n",
    "                                        args=params, \n",
    "                                        n_burn=num_burn, \n",
    "                                        n_steps=N_iter, \n",
    "                                        variable_names=None)\n",
    "    \n",
    "    while len(df_samples) == 0:\n",
    "        sigma = tune_sigma(accept_rate, sigma)\n",
    "        df_samples, accept_rate = mh_sample(log_test_distribution, \n",
    "                                            x0, \n",
    "                                            sigma, \n",
    "                                            args=params, \n",
    "                                            n_burn=num_burn, \n",
    "                                            n_steps=N_iter, \n",
    "                                            variable_names=None)\n",
    "        \n",
    "    return df_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of iteration\n",
    "N_iter = 100000\n",
    "\n",
    "# Names of strains\n",
    "strain = ['ASH','AVA','WT']\n",
    "\n",
    "# Corresponding parameters\n",
    "params = [[5.5, 18., 124, 39], \n",
    "          [8., 3., 124, 91],\n",
    "          [0.2, 8., 126, 13]]\n",
    "\n",
    "# Corresponding initial steps\n",
    "x0s = [0.3, 0.8, 0.1]\n",
    "\n",
    "# Initialize data frame\n",
    "df_samples_mh = pd.DataFrame()\n",
    "\n",
    "# Initialize histogram plot\n",
    "p3 = bokeh.plotting.figure(height=300, width=400, title='Metropolis-Hastings sampler')\n",
    "\n",
    "for i, strain_name in enumerate(strain):\n",
    "    temp = hw7_sampling(x0s[i], sigma, params[i], log_test_distribution, 2000, N_iter)\n",
    "    temp['Strain'] = strain_name\n",
    "    p3 = bebi103.viz.histogram(temp['theta'],\n",
    "                               p=p3,\n",
    "                               bins=35,\n",
    "                               line_width=2,\n",
    "                               density=True,\n",
    "                               x_axis_label='theta',\n",
    "                               y_axis_label='g(theta|y)',\n",
    "                               color = color_palette[i])\n",
    "    \n",
    "    df_samples_mh = pd.concat([df_samples_mh, temp])\n",
    "        \n",
    "df_samples_mh = df_samples_mh.reset_index(drop=True)\n",
    "\n",
    "# ECDF collection\n",
    "p4 = bebi103.viz.ecdf_collection(data=df_samples_mh,\n",
    "                                cats='Strain',\n",
    "                                val='theta',\n",
    "                                formal=True,\n",
    "                                line_width=2,\n",
    "                                plot_width=600,\n",
    "                                plot_height=300)\n",
    "\n",
    "# Compare samples from MH sampler and Stan sampler\n",
    "bokeh.io.show(bokeh.layouts.gridplot([p1, p2, p3, p4], ncols=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They look almost the same, so the MH sampler of ours should be a good sampler in this case, but as we tried, the number of iteration needs to be much larger than the Stan sampler to have a similarly clean histrogram, so the performance of the Stan sampler should still be better than ours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c)**\n",
    "\n",
    "Initially, if we haven't done anything about this model, we may need a new one to draw samples for the difference in reversal probability $\\delta_{12}$, which we have as below. The model would draw samples from two independent posteriors for those two strains and give the transformed quantities which are the $\\delta$ that we are looking for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_code_diff_gen = \"\"\"\n",
    "data { \n",
    "  real a1;\n",
    "  real b1;\n",
    "  real a2;\n",
    "  real b2;\n",
    "  int Nt1;\n",
    "  int n1;\n",
    "  int Nt2;\n",
    "  int n2;\n",
    "}\n",
    "\n",
    "\n",
    "parameters {\n",
    "  real<lower=0, upper=1> theta1;\n",
    "  real<lower=0, upper=1> theta2;\n",
    "}\n",
    "\n",
    "\n",
    "model {\n",
    "  // Priors\n",
    "  theta1 ~ beta(a1, b1);\n",
    "  theta2 ~ beta(a2, b2);\n",
    "\n",
    "  // Likelihood\n",
    "  n1 ~ binomial(Nt1, theta1);\n",
    "  n2 ~ binomial(Nt2, theta2);\n",
    "}\n",
    "\n",
    "generated quantities {\n",
    "  real dtheta = theta2 - theta1;\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_diff_gen = bebi103.stan.StanModel(file='hw72_diff_gen.stan')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then similarly, we have a function to draw samples out of this transformed model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mcmc_theta_diff_sampling(sm_gen, params , N_iter=100000):\n",
    "    '''Sample out of the posterior'''\n",
    "    # Pass parameters\n",
    "    alpha1, beta1, Num_t1, num1, alpha2, beta2, Num_t2, num2 = params\n",
    "    \n",
    "    data = dict(a1=alpha1,\n",
    "                b1=beta1,\n",
    "                a2=alpha2,\n",
    "                b2=beta2,\n",
    "                Nt1=Num_t1,\n",
    "                n1=num1,\n",
    "                Nt2=Num_t2,\n",
    "                n2=num2)\n",
    "    samples = sm_gen.sampling(data=data, iter=N_iter)\n",
    "    \n",
    "    return bebi103.stan.to_dataframe(samples, diagnostics=False, inc_warmup=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of iteration\n",
    "N_iter = 10000\n",
    "\n",
    "# Names of the strains\n",
    "strain = ['ASH','AVA','WT']\n",
    "\n",
    "# Parameters for each strain\n",
    "params = [[5.5, 18., 124, 39], \n",
    "          [8., 3., 124, 91],\n",
    "          [0.2, 8., 126, 13]]\n",
    "\n",
    "# Index of the strains to compare\n",
    "strain_diff = [[0,1],[2,0],[2,1]]\n",
    "\n",
    "# Initilize data frame\n",
    "df_diff_mcmc = pd.DataFrame()\n",
    "\n",
    "p5 = bokeh.plotting.figure(width=400, height=300, title='Difference of theta')\n",
    "\n",
    "\n",
    "for i, cp in enumerate(strain_diff):\n",
    "    para_temp = params[cp[0]] + params[cp[1]]\n",
    "    temp = mcmc_theta_diff_sampling(sm_diff_gen, para_temp, N_iter)\n",
    "    temp['Strain'] = strain[cp[0]] + '-' + strain[cp[1]]\n",
    "    p5 = bebi103.viz.histogram(temp['dtheta'],\n",
    "                               p=p5,\n",
    "                               bins=35,\n",
    "                               line_width=2,\n",
    "                               density=True,\n",
    "                               x_axis_label='delta theta',\n",
    "                               y_axis_label='g(delta theta|y)',\n",
    "                               color = color_palette[i])    \n",
    "    df_diff_mcmc = pd.concat([df_diff_mcmc, temp])\n",
    "        \n",
    "df_diff_mcmc = df_diff_mcmc.reset_index(drop=True)\n",
    "\n",
    "p6 = bebi103.viz.ecdf_collection(data=df_diff_mcmc, \n",
    "                                cats='Strain',\n",
    "                                val='dtheta',\n",
    "                                formal=True,\n",
    "                                line_width=2,\n",
    "                                plot_width=600,\n",
    "                                plot_height=300)\n",
    "\n",
    "bokeh.io.show(bokeh.layouts.gridplot([p5, p6], ncols=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, thanks to the fact that we do draw independently samples out of each posterior, we can have a easier way to do this, where we can just pair the samples from two posterior and do the substraction for each pair. In this way, similar to the way we do marginalization, we can have the posterior of difference in $\\theta$ with ease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Names of the strains\n",
    "strain = ['ASH','AVA','WT']\n",
    "\n",
    "# Index of strains to compare\n",
    "strain_diff = [[0,1],[2,0],[2,1]]\n",
    "\n",
    "# Initilize the data frame\n",
    "df_diff_mcmc_easy = pd.DataFrame()\n",
    "\n",
    "p7 = bokeh.plotting.figure(width=400, height=300, title='Difference of theta, easy substration')\n",
    "\n",
    "\n",
    "for i, cp in enumerate(strain_diff):\n",
    "    temp = pd.DataFrame(data=(df_samples_mh.loc[df_samples_mh['Strain']==strain[cp[1]],'theta'].values - \\\n",
    "                             df_samples_mh.loc[df_samples_mh['Strain']==strain[cp[0]],'theta'].values),\n",
    "                        columns={'dtheta'})\n",
    "    temp['Strain'] = strain[cp[0]] + '-' + strain[cp[1]]\n",
    "    p7 = bebi103.viz.histogram(temp['dtheta'],\n",
    "                               p=p7,\n",
    "                               bins=35,\n",
    "                               line_width=2,\n",
    "                               density=True,\n",
    "                               x_axis_label='delta theta',\n",
    "                               y_axis_label='g(delta theta|y)',\n",
    "                               color = color_palette[i])    \n",
    "    df_diff_mcmc_easy = pd.concat([df_diff_mcmc_easy, temp])\n",
    "        \n",
    "df_diff_mcmc_easy = df_diff_mcmc_easy.reset_index(drop=True)\n",
    "\n",
    "p8 = bebi103.viz.ecdf_collection(data=df_diff_mcmc_easy, \n",
    "                                cats='Strain',\n",
    "                                val='dtheta',\n",
    "                                formal=True,\n",
    "                                line_width=2,\n",
    "                                plot_width=600,\n",
    "                                plot_height=300)\n",
    "\n",
    "# Compare results from two methods\n",
    "bokeh.io.show(bokeh.layouts.gridplot([p7, p8, p5, p6], ncols=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They look very similar to each other. Thus, we can have the distribution of interest easily if we have samples drawn out of the each strain's posterior. This is a huge advantage over analytical posterior distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPython 3.7.1\n",
      "IPython 7.0.1\n",
      "\n",
      "numpy 1.15.1\n",
      "scipy 1.1.0\n",
      "bokeh 0.13.0\n",
      "jupyterlab 0.35.2\n"
     ]
    }
   ],
   "source": [
    "%watermark -v -p numpy,scipy,bokeh,jupyterlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
