{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 7: exercise\n",
    "\n",
    "(c) 2018 Justin Bois. With the exception of pasted graphics, where the source is noted, this work is licensed under a [Creative Commons Attribution License CC-BY 4.0](https://creativecommons.org/licenses/by/4.0/). All code contained herein is licensed under an [MIT license](https://opensource.org/licenses/MIT).\n",
    "\n",
    "This document was prepared at [Caltech](http://www.caltech.edu) with financial support from the [Donna and Benjamin M. Rosen Bioengineering Center](http://rosen.caltech.edu).\n",
    "\n",
    "<img src=\"caltech_rosen.png\">\n",
    "\n",
    "*This tutorial exercise was generated from an Jupyter notebook.  You can download the notebook [here](t7_exercise.ipynb). Use this downloaded Jupyter notebook to fill out your responses.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "**a)** Explain in words why being able to sample out of a probability distribution is useful.\n",
    "\n",
    "Being able to sample out of a probability distribution is useful because it's easy to visualize the distribution, marginalize over parameters, and compute expectations or other statistical functionals.\n",
    "\n",
    "**b)** Explain in words the basic idea behind Markov chain Monte Carlo.\n",
    "\n",
    "A walker takes a random walk such that the probability that the walker arrives at a particular point is proportional to the probability distribution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "Why is it important to warm up a sampler?\n",
    "\n",
    "It's important to warm up the sampler since the first few steps can be in a region of parameter space with very low probability, and it takes a while for the walker to get to the region of higher probability. Once the walker reaches those higher probability regions, it likely won't come back to its initial starting point of low probability. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "Say we used MCMC to sample a posterior distribution that had 6 parameters, $g(a_1,a_2,a_3,a_4,a_5,a_6\\mid y)$\n",
    ". From the MCMC samples, how can we get samples for the marginalized distribution $g(a_3 \\mid y)$?\n",
    "\n",
    "We ignore the values for $a_2, a_3, a_4, a_5,$ and $a_6$? I don't think I understand how ignoring the other parameters gives you the marginalized distribution for the variable that wasn't ignored. Is ignoring the other parameters the same as if you integrated over all the other parameters somehow?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "What does it mean for a model to be nonidentifiable?\n",
    "\n",
    "A nonidentifiable model is a model where we can't unambiguously determine the parameter values."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
