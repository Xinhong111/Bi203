{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 10: exercise\n",
    "\n",
    "(c) 2018 Justin Bois. With the exception of pasted graphics, where the source is noted, this work is licensed under a [Creative Commons Attribution License CC-BY 4.0](https://creativecommons.org/licenses/by/4.0/). All code contained herein is licensed under an [MIT license](https://opensource.org/licenses/MIT).\n",
    "\n",
    "This document was prepared at [Caltech](http://www.caltech.edu) with financial support from the [Donna and Benjamin M. Rosen Bioengineering Center](http://rosen.caltech.edu).\n",
    "\n",
    "<img src=\"caltech_rosen.png\">\n",
    "\n",
    "*This tutorial exercise was generated from an Jupyter notebook.  You can download the notebook [here](t10_exercise.ipynb). Use this downloaded Jupyter notebook to fill out your responses.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "Give an example of a situation where it is ok to throw out data you acquired.\n",
    "\n",
    "When you set your instrument to the wrong settings on accident e.g. used the wrong excitation laser. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "If you were to summarize the posterior with a MAP/error bar using optimization (not MCMC), would it be easier to use the Student-t method of dealing with outliers or the good/bad data model? Why?\n",
    "\n",
    "Not sure..sounds like a math thing. Maybe student-t since it's less complicated than a mixture model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "Describe in words the generative model behind the use of all three outlier methods discussed in the tutorial (median plugin estimate, Student-t likelihood, good-bad data model).\n",
    "\n",
    "For the median plugin estimate, the data generative process is Gaussian. For the Student-t likelihood, the likelihood is Student-t and the priors are half normal. For the good-bad data model, the generative model is a mixture of Gaussians. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
