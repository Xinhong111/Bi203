{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 7: exercise\n",
    "\n",
    "(c) 2018 Justin Bois. With the exception of pasted graphics, where the source is noted, this work is licensed under a [Creative Commons Attribution License CC-BY 4.0](https://creativecommons.org/licenses/by/4.0/). All code contained herein is licensed under an [MIT license](https://opensource.org/licenses/MIT).\n",
    "\n",
    "This document was prepared at [Caltech](http://www.caltech.edu) with financial support from the [Donna and Benjamin M. Rosen Bioengineering Center](http://rosen.caltech.edu).\n",
    "\n",
    "<img src=\"caltech_rosen.png\">\n",
    "\n",
    "*This tutorial exercise was generated from an Jupyter notebook.  You can download the notebook [here](t7_exercise.ipynb). Use this downloaded Jupyter notebook to fill out your responses.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "**a)** Explain in words why being able to sample out of a probability distribution is useful.\n",
    "\n",
    "**b)** Explain in words the basic idea behind Markov chain Monte Carlo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) If we drew many samples from the probability distribution, we could reconstruct the posterior of the distribution from the samples by ways such as making histogram.\n",
    "\n",
    "b) The basic idea behind Markov chain Monte Carlo is by drawing many samples which the probability of choosing given values of a set of parameters is proportional to the posterior probability of that set of values, we could reconstruct the posterior from the samples.The more steps there are, the more closely the distribution of the sample matches the actual desired distribution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "Why is it important to warm up a sampler?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we just start the walker at the certain position in the parameter space, mostlikely the first few steps were in a place where has incredibly low probability, and these few steps could be over-weighted in the following analysis, so it's better to let it walk for a while without checking the sample first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "Say we used MCMC to sample a posterior distribution that had 6 parameters, $g(a_1,a_2,a_3,a_4,a_5,a_6\\mid y)$\n",
    ". From the MCMC samples, how can we get samples for the marginalized distribution $g(a_3 \\mid y)$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could ignore the other parameters and plot the ECDF using the sample we get back from MCMC. But I am not quite sure about ignoring other factors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "What does it mean for a model to be nonidentifiable?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When two or more parametrizations are observationally equivalent, the model is nonidentifiable. In such a model, it is theoretically impossible to learn the true values of all underlying parameters after obtaining an infinite number of observations from it. In some cases, even though a model is non-identifiable, it is still possible to learn the true values of a certain subset of the model parameters. In this case we say that the model is partially identifiable. In other cases it may be possible to learn the location of the true parameter up to a certain finite region of the parameter space, in which case the model is set identifiable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
